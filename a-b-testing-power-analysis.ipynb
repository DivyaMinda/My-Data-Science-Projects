{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":30684,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"**Goal** - In this project, we will deep dive into Power Analysis required for successful implemental of A/B Testing. The focus is on executing power analysis  in Python.\n\nI have created a hypothetical business problem inspired by various A/B testing use cases I have worked on in my past organizations. \n\n**Business Problem** - ABC Co, a monthly subscription based grocery supplies business, is looking to expand its member base. \nThe pricing team proposes a 10% discount on the first month's membership fee to attract new members and suggests revamping the current Direct Mail marketing campaign to prominently highlight this offer. They belive/ hypothesis that this offer can increase the subscription rate from 15% to 18% \n\nLets assume this team has already done aceessment of cost-effectiveness of this offer, and they conclude that even with 10% discount, the first month of enrollment will be ROI positive if the enrollment rate increases by 3% points. \n\nMarketing team wants to know whether this incentive will indeed increase the enrollment rate from 15% to 18%. \n\nYou, the Data Scientist at ABC Co., decide to setup an A/B testing experiment to access this hypothesis. \n\nBefore we dive deeper in A/B testing experiment setup, lets review some terms/ metrics\n\n**What is A/B testing?**\nA/B testing is a way to compare multiple versions of a single variable, for example by testing a subject's response to variant A against variant B, and determining which of the variants is more effective. (Wikipedia Definition)\n\nLets map this definition to the business problem. We want to compare enrollment rate (subject's response) for 2 versions of marketing Direct Mail (Current version vs new version with 10% discount) to know which of these variants is more effective.\n \n\n**Metric Defintions **\n\nEnrollment Rate = Number of audience enrolled/ total audience targeted \n\nCurrent Enrollment Rate (baseline) = 15% \n\nExpected Enrollment Rate = 18% \n\nAbsolute Lift = Expected Enrollment Rate - Current Enrollment Rate\n\nRelative Lift = (Expected Enrollment Rate - Current Enrollment Rate)/ Current Enrollment Rate\n","metadata":{}},{"cell_type":"markdown","source":"To design the A/B test experiment, follow the steps below- \n\n**Step 1** - Clearly define the Null hypothesis and Alternate hypothesis \n\nWe have two target audience groups- \n\nTreatment - will receive Direct Mail with 10% discount offer\n\nControl - will receive current version of Direct Mail (meaning no discounts) \n\nLets say, we run the marketing campaign and record the enrollment rate towards the end of campaign. Let x be enrollment rate for Treatment and y be enrollment rate for Control \n\n**Null hypothesis (Ho): x = y** \n\nThe enrollment rate for Treatment and Control group are not differnt. So if you observe a difference that is likely due to chance \n\n\n**Alternate hypothesis (H1): x>y**\n\nThere is difference between enrollment rate for Treatment and Control more extreme than what random chance can produce. This is the challenger to the null hypothesis\n","metadata":{}},{"cell_type":"markdown","source":"**Step 2** - Identify what should be the minimum sample size (number of target audience per group) to ensure statistically significant results which minimizes the Type I and Type II errors \n\n**Type I error** - Incorrectly rejecting the Null hypothesis when it is actually true\n\n**Type II error** - Incorrectly accepting the Null hypothesis when it is actually false \n\nMinimizing these errors will ensure that results observed are statistically significant (not due to random chance). \n\nTo achive this, we will implement hypothesis testing which outputs the probability of obtaining the observed results by random chance. This is called **p-value**.\n\n\n**4 parameters are key in hypothesis testing - **\n\n**Baseline Rate** - this is the current enrollment rate. In our case, 15%.\n\n**Effect Size** - It is the magnitude of the difference in enrollment rates between two groups/\n\nCohen’s d is one of the measures to calculate effect size which we will use here.\n\n**Sample Size** - this is the minimum required samples in each group (treatment and control) to get significant results. We need to find out the sample size. \n\n**Statistical Significance level** - This is probability threshold against which we compare the output of hypothesis testing. This threshold is typically set to 5% or 1%. This helps in minimizing Type I error.\n\n**Statistical Power** - This is probability of correctly rejecting the null hypothesis. This probability threshold is usually set to 80% and it reduces Type II error \n\nPower analysis function is such that if you know 3 of the above variables you can find the value of 4th variable. \n\nBelow is power analysis implementation in Python\n\nOur goal is to find minimum sample size with a statistical significance level of 5%, statistical power of 20% and the effect size (which we will calculate).\nLet's say we want to have a 50/50 distribution of sample audience in each group.\n\n\n\n","metadata":{}},{"cell_type":"markdown","source":"**Effect Size Calculation**\n\nCohen’s d formula for effect size \n(x1-x2)/ s \nwhere x1 is mean of group 1 and x2 is mean of group 2 and s is the pooled standard deviation of both groups \n\nIn this case, the metric is enrollment rate with binary outcome (enroll/ not  enroll). So based on Bernoulli distribution \nMean of treatment group is expected enrollment rate (p1) = 0.18  \n\nStandard deviation of treatment group (s1) = sqrt(p1(1-p1))\n\nMean of control group is baseline enrollment rate (p2) = 0.15 \n\nStandard deviation of control group (s2) = sqrt(p2(1-p2))\n\npooled standard deviation = sqrt((s1^2 + s2^2)/2)\n\nBelow is python function I have created to calculate the effect size ","metadata":{}},{"cell_type":"code","source":"import numpy as np \nimport pandas as pd \n\nimport numpy as np \n\n#baseline_rate = 15% \n\n#expected_rate = 18% \n\ndef calculate_effect_size(baseline_rate, expected_rate):\n    # Calculate standard deviations for both rates\n    std_base = np.sqrt(baseline_rate * (1 - baseline_rate))\n    std_exp = np.sqrt(expected_rate * (1 - expected_rate))\n    \n    # Calculate the pooled standard deviation\n    pooled_std = np.sqrt((std_base**2 + std_exp**2) / 2)\n    \n    # Calculate the effect size\n    effect_size = (expected_rate - baseline_rate) / pooled_std\n    return effect_size\n\neffect_size = calculate_effect_size(0.15, 0.18)\nprint(f'effect size is {effect_size}')","metadata":{"execution":{"iopub.status.busy":"2024-04-10T18:07:03.180859Z","iopub.execute_input":"2024-04-10T18:07:03.181581Z","iopub.status.idle":"2024-04-10T18:07:04.474695Z","shell.execute_reply.started":"2024-04-10T18:07:03.181535Z","shell.execute_reply":"2024-04-10T18:07:04.473533Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"effect size is 0.0808892776909605\n","output_type":"stream"}]},{"cell_type":"markdown","source":"**Power Analysis** \n\nHere we will use the python package - statsmodels.stats.power to calculate the sample size\n\nThere are different power analysis functions in this package for t-tests, normal based test, F-tests and Chisquare goodness of fit test.\n\nIn our case a Z test is suitable so we will use the zt_ind_solve_power() function. \n(reference - https://www.statsmodels.org/dev/stats.html#proportion) \n\nWe will input the effect size calculated above along with statistical significance level of 5% (alpha) and statistical power of 80%.\n","metadata":{}},{"cell_type":"code","source":"import statsmodels.stats.power as smp\n\n\n\n# effect_size = 0.1  # Effect size (Cohen's d)\nalpha = 0.05       # Significance level\npower = 0.8        # Desired power\nnobs1 = None       # Number of observations in group 1 (None for unknown) -- This is the sample size we need to find\n\n#additional parameters required \nratio = 1 # since we want to split audience 50% in Treatment and 50% in control, Treatment/Control ratio is set to 1 \n\n#Since the alternative hypothesis is that x>y we want to use one-sided test \n#default value for this parameter is two-sided which can be used if the alternative hypothesis is x not equal to y\n#the value can also be set to smaller for alternative hypothesis x<y\nalternative = 'larger' \n\n# Perform power analysis\npower_analysis = smp.zt_ind_solve_power(effect_size=effect_size, nobs1=nobs1, alpha=alpha, power=power, ratio=ratio, alternative=alternative)\n\nprint(\"Required Sample Size:\", power_analysis)\n\n","metadata":{"execution":{"iopub.status.busy":"2024-04-10T18:07:07.852097Z","iopub.execute_input":"2024-04-10T18:07:07.852655Z","iopub.status.idle":"2024-04-10T18:07:09.365093Z","shell.execute_reply.started":"2024-04-10T18:07:07.852622Z","shell.execute_reply":"2024-04-10T18:07:09.363760Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"Required Sample Size: 1889.8016605999433\n","output_type":"stream"}]},{"cell_type":"markdown","source":"Above results suggest that, we need atleast 1890 target audience in each group to ensure statistically significant results when A/B test is conducted. \n\nSo, lets say we have 60,000 target audience. \nOf these we will take a random sample which is 2 times 1890 i.e. 3780. \n\nRandom sample will ensure that the sample is representative of the population. \n\nWe will then split them in two groups, Treatment and Control following a 50-50 distribution \n\nBelow is example code to achieve this","metadata":{}},{"cell_type":"code","source":"#creating a dataframe which stores ID of  60,000 target audience \ndf = pd.DataFrame({'id': range(1, 60001)})\n\nprint(df.head())","metadata":{"execution":{"iopub.status.busy":"2024-04-10T18:07:12.131620Z","iopub.execute_input":"2024-04-10T18:07:12.132064Z","iopub.status.idle":"2024-04-10T18:07:12.148350Z","shell.execute_reply.started":"2024-04-10T18:07:12.132033Z","shell.execute_reply":"2024-04-10T18:07:12.147217Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"   id\n0   1\n1   2\n2   3\n3   4\n4   5\n","output_type":"stream"}]},{"cell_type":"code","source":"#take random sample of size 3780 from this pool \ndf_sample = df.sample(3780)\nprint(df_sample.head())","metadata":{"execution":{"iopub.status.busy":"2024-04-10T18:09:07.505176Z","iopub.execute_input":"2024-04-10T18:09:07.505610Z","iopub.status.idle":"2024-04-10T18:09:07.523536Z","shell.execute_reply.started":"2024-04-10T18:09:07.505578Z","shell.execute_reply":"2024-04-10T18:09:07.522172Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"          id\n18158  18159\n31122  31123\n2831    2832\n16058  16059\n46307  46308\n","output_type":"stream"}]},{"cell_type":"code","source":"#Create Treatment and Control group \nTreatment_df = df_sample.sample(1890)\n\n#The control group is all IDs in df_sample excluding the ones in Treatment \nControl_df = df_sample[~df_sample['id'].isin(Treatment_df['id'])]\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Callout**\n\nOften, in business setup we want to optimize profits while we continue learning what works/ does not work via A/B testing. \n\nHence, in a business case like this we may want to explore 80-20 distribution of Treatment and Control - meaning 80% audience will be in treatment and get the discount offer while 20% will be in control. \n\nFor this scenario, we can run the previous sample power analysis function by changing the ratio parameter to 4 and find the new sample size requirements. \n\nLet us run the code below. ","metadata":{}},{"cell_type":"code","source":"\n# effect_size = 0.1  # Effect size (Cohen's d)\nalpha = 0.05       # Significance level\npower = 0.8        # Desired power\nnobs1 = None       # Number of observations in group 1 (None for unknown) -- This is the sample size we need to find\n\n#additional parameters required \nratio = 4 # since we want to split audience 80% in Treatment and 20% in control, Treatment/Control ratio is set to 1 \n\n#Since the alternative hypothesis is that x>y we want to use one-sided test \n#default value for this parameter is two-sided which can be used if the alternative hypothesis is x not equal to y\n#the value can also be set to smaller for alternative hypothesis x<y\nalternative = 'larger' \n\n# Perform power analysis\npower_analysis = smp.zt_ind_solve_power(effect_size=effect_size, nobs1=nobs1, alpha=alpha, power=power, ratio=ratio, alternative=alternative)\n\nprint(\"Required Sample Size:\", power_analysis)\n\n","metadata":{"execution":{"iopub.status.busy":"2024-04-10T18:18:21.777814Z","iopub.execute_input":"2024-04-10T18:18:21.778264Z","iopub.status.idle":"2024-04-10T18:18:21.793328Z","shell.execute_reply.started":"2024-04-10T18:18:21.778229Z","shell.execute_reply":"2024-04-10T18:18:21.791969Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"Required Sample Size: 1181.1260396328687\n","output_type":"stream"}]},{"cell_type":"markdown","source":"**Interpreting the sample size for 80-20 distribution**\n\nIn this case, the sample size we get from power analysis is 1181. This is the minimum sample size of the smallest group i.e. Control. \n\nTo get the sample size for Treatment we multiply this by 4 (remember the ratio we set) \nSo, sample size for Treatment is 4724","metadata":{}},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"markdown","source":"","metadata":{}}]}